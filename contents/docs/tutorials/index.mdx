---
title: Tutorials
description: New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.
keywords: ["navigation", "sidebar", "menus", "mdx", "nextjs", "documents"]
---

## Get started

Familiarize yourself with LangChain's open-source components by building simple applications.

If you're looking to get started with chat models, vector stores, or other LangChain components from a specific provider, check out our supported integrations.

    - **[Chat models and prompts](/docs/tutorials/llm_chain)**: Build a simple LLM application with prompt templates and chat models.
    - **[Semantic search](/docs/tutorials/retrievers)**: Build a semantic search engine over a PDF with document loaders, embedding models, and vector stores.
    - **[Classification](/docs/tutorials/classification)**: Classify text into categories or labels using chat models with structured outputs.
    - **[Extraction](/docs/tutorials/extraction)**: Extract structured data from text and other unstructured media using chat models and few-shot examples.

Refer to the how-to guides for more detail on using all LangChain components.

## Orchestration

Get started using LangGraph to assemble LangChain components into full-featured applications.

    - **Chatbots**: Build a chatbot that incorporates memory.
    - **Agents**: Build an agent with LangGraph.js that interacts with external tools.
    - **Retrieval Augmented Generation (RAG) Part 1**: Build an application that uses your own documents to inform its responses.
    - **Retrieval Augmented Generation (RAG) Part 2**: Build a RAG application that incorporates a memory of its user interactions and multi-step retrieval.
    - **Question-Answering with SQL**: Build a question-answering system that executes SQL queries to inform its responses.
    - **Summarization**: Generate summaries of (potentially long) texts.
    - **Question-Answering with Graph Databases**: Build a question-answering system that queries a graph database to inform its responses.

## LangSmith

LangSmith allows you to closely trace, monitor and evaluate your LLM application. It seamlessly integrates with LangChain, and you can use it to inspect and debug individual steps of your chains as you build.

LangSmith documentation is hosted on a separate site. You can peruse **[LangSmith tutorials here](https://docs.smith.langchain.com/)**.

### Evaluation

LangSmith helps you evaluate the performance of your LLM applications. The below tutorial is a great way to get started:

    - **[Evaluate your LLM application](https://docs.smith.langchain.com/evaluation/tutorials/evaluation)**